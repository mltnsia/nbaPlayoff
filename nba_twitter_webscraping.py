# -*- coding: utf-8 -*-
"""[Cleaned] NBA Twitter Data Analytics.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QYbvQxo928tW5p6uPTQDK5_nc2agmDa7

## **1. Scrape Twitter Data for NBA**
"""

!pip install snscrape

import os

# Using OS library to call CLI commands in Python
os.system("snscrape --jsonl --max-results 10000 --since 2022-04-11 twitter-search 'NBA Bucks until:2022-10-17' > text-query-tweets.json")

import pandas as pd

# Reads the json generated from the CLI commands above and creates a pandas dataframe
tweets_df = pd.read_json('text-query-tweets.json', lines=True)

tweets_df.head()

tweets_df.to_csv()

"""##**2. Data Loading**"""

df1 = tweets_df[['date', 'rawContent','renderedContent','user','replyCount','retweetCount','likeCount','lang','place','hashtags','viewCount']].copy()

df1.head()

print(df1.shape)

"""## **3. Twitter Data Cleaning, Preprocessing and Exploratory Data Analysis**"""

df1=df1.drop_duplicates('renderedContent')

print(df1.shape)

df1.head()

df1.date.value_counts()

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns

import nltk

stop=nltk.download('stopwords')

from nltk.corpus import stopwords
stop = stopwords.words('english')
df1['renderedContent'].apply(lambda x: [item for item in x if item not in stop])
df1.shape

!pip install tweet-preprocessor

#Remove unnecessary characters
punct =['%','/',':','\\','&amp;','&',';', '?']

def remove_punctuations(text):
    for punctuation in punct:
        text = text.replace(punctuation, '')
    return text

df1['renderedContent'] = df1['renderedContent'].apply(lambda x: remove_punctuations(x))

#Drop tweets which have empty text field
df1['renderedContent'].replace(' ', np.nan, inplace=True)
df1.dropna(subset=['renderedContent'], inplace=True)
len(df1)

df1 = df1.reset_index(drop=True)
df1.sample(5)

"""## **4. Sentiment Analysis**"""

!pip install textblob

from textblob import TextBlob

def get_subjectivity(text):
    return TextBlob(text).sentiment.subjectivity

def get_polarity(text):
    return TextBlob(text).sentiment.polarity

df1['subjectivity'] = df1['renderedContent'].apply(get_subjectivity)
df1['polarity'] = df1['renderedContent'].apply(get_polarity)
df1.head()

# Obtain polarity scores generated by TextBlob
df1['textblob_score'] = df1['renderedContent'].apply(lambda x: TextBlob(x).sentiment.polarity)

neutral_threshold = 0.05

# Convert polarity score into sentiment categories
df1['textblob_sentiment'] = df1['textblob_score'].apply(lambda c: 'Positive' if c >= neutral_threshold else ('Negative' if c <= -(neutral_threshold) else 'Neutral'))

textblob_df = df1[['renderedContent', 'textblob_sentiment', 'likeCount']]
textblob_df

textblob_df['textblob_sentiment'].value_counts()

textblob_df['textblob_sentiment'].value_counts().plot.barh(title='Sentiment Analysis ', color='orange', width=.4, figsize=(10, 8), stacked = True)